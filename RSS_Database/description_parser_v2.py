import re
from datetime import datetime
from typing import Dict, Optional, List

# AA'nÄ±n kullandÄ±ÄŸÄ± sabit kategori listesi
AA_CATEGORIES = [
    'Politika',
    'Ekonomi', 
    'Teknoloji',
    'SaÄŸlÄ±k',
    'Spor',
    'GÃ¼ncel',
    'DÃ¼nya',
    'KÃ¼ltÃ¼r Sanat',
    'Bilim',
    'EÄŸitim',
    'YaÅŸam',
    'Ã‡evre', 
    'turkiye',
    'kultur',
]

def parse_aa_description_advanced(description: str) -> Dict[str, Optional[str]]:
    """
    AA RSS feed description'Ä±nÄ± parse eder
    
    Format: [Kategori][BaÅŸlÄ±k][Ã–zet][Yazar][Tarih]
    
    Ã–rnekler:
    - "PolitikaBakan MemiÅŸoÄŸlu: Åehir hastanelerimiz...BaÅŸak Akbulut Yazar  |17.05.2025"
    - "Spor,BasketbolKadÄ±n basketbolunda 46. sezon...Salih UlaÅŸ Åahan  |03.10.2025"
    
    Returns:
        dict: TÃ¼m parse edilmiÅŸ metadata
    """
    
    if not description:
        return None
    
    result = {
        'category': None,
        'subcategory': None,
        'title': None,
        'summary': None,
        'author': None,
        'published_date': None,
        'updated_date': None,
        'raw_description': description
    }
    
    working_text = description.strip()
    
    # 1. TARÄ°H - En sonda (DD.MM.YYYY formatÄ±nda)
    date_pattern = r'(\d{2}\.\d{2}\.\d{4})(?:\s*-\s*GÃ¼ncelleme\s*:\s*(\d{2}\.\d{2}\.\d{4}))?$'
    date_match = re.search(date_pattern, working_text)
    
    if date_match:
        result['published_date'] = date_match.group(1)
        result['updated_date'] = date_match.group(2)
        working_text = working_text[:date_match.start()].strip()
    
    # 2. YAZAR - Tarihten Ã¶nce, " |" ile biter
    # TÃ¼rkÃ§e karakterlere izin ver, 2-3 kelimelik isimler
    author_pattern = r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+){1,3})\s+\|$'
    author_match = re.search(author_pattern, working_text)
    
    if author_match:
        result['author'] = author_match.group(1).strip()
        working_text = working_text[:author_match.start()].strip()
    
    # 3. KATEGORÄ° - Sabit listeden eÅŸleÅŸtirme
    # En uzun kategoriyi Ã¶nce kontrol et (Ã¶rn: "KÃ¼ltÃ¼r Sanat" Ã¶nce, "KÃ¼ltÃ¼r" sonra)
    sorted_categories = sorted(AA_CATEGORIES, key=len, reverse=True)
    
    category_found = None
    subcategory_found = None
    
    for cat in sorted_categories:
        # Kategori baÅŸta mÄ± kontrol et
        if working_text.startswith(cat):
            category_found = cat
            working_text = working_text[len(cat):].strip()
            
            # Alt kategori var mÄ± kontrol et (virgÃ¼l veya baÅŸka kategori)
            # Ã–rnek: "Spor,Basketbol" veya "SporBasketbol"
            if working_text.startswith(','):
                working_text = working_text[1:].strip()
                # VirgÃ¼lden sonra baÅŸka kategori varsa alt kategori
                for subcat in sorted_categories:
                    if working_text.startswith(subcat):
                        subcategory_found = subcat
                        working_text = working_text[len(subcat):].strip()
                        break
            else:
                # VirgÃ¼l yoksa, direkt baÅŸka kategori olabilir
                for subcat in sorted_categories:
                    if subcat != category_found and working_text.startswith(subcat):
                        subcategory_found = subcat
                        working_text = working_text[len(subcat):].strip()
                        break
            
            break
    
    result['category'] = category_found.lower() if category_found else None
    result['subcategory'] = subcategory_found.lower() if subcategory_found else None
    
    # 4. BAÅLIK ve Ã–ZET
    # Kalan metin: BaÅŸlÄ±k + Ã–zet
    # BaÅŸlÄ±k: Genellikle bÃ¼yÃ¼k harfle baÅŸlar, kÄ±sa bir ifade
    # Ã–zet: BÃ¼yÃ¼k harfle devam eder, daha uzun aÃ§Ä±klama
    
    # Strateji: Ä°ki bÃ¼yÃ¼k harfli cÃ¼mle varsa, ilki baÅŸlÄ±k, ikincisi Ã¶zet
    # Pattern: BÃ¼yÃ¼k harfle baÅŸlayan cÃ¼mleler
    
    # BÃ¼yÃ¼k harfle baÅŸlayan kÄ±sÄ±mlarÄ± bul
    sentences = re.split(r'(?<=[.!?])\s+(?=[A-ZÃ‡ÄÄ°Ã–ÅÃœ])', working_text)
    
    if len(sentences) >= 2:
        # Ä°lk cÃ¼mle baÅŸlÄ±k, geri kalanÄ± Ã¶zet
        result['title'] = sentences[0].strip()
        result['summary'] = ' '.join(sentences[1:]).strip()
    elif len(sentences) == 1:
        # Tek cÃ¼mle varsa, bÃ¼yÃ¼k harfli ilk kÄ±smÄ± baÅŸlÄ±k yap
        # EÄŸer Ã§ok uzunsa (150+ karakter), bir yerde kes
        text = sentences[0]
        
        # Uzun mu kontrol et
        if len(text) > 150:
            # Ä°lk 150 karakterde nokta, soru iÅŸareti veya iki nokta Ã¼st Ã¼ste varsa kes
            potential_breaks = [
                text.find('.', 50, 150),
                text.find(':', 50, 150),
                text.find('?', 50, 150),
            ]
            potential_breaks = [x for x in potential_breaks if x > 0]
            
            if potential_breaks:
                break_point = min(potential_breaks) + 1
                result['title'] = text[:break_point].strip()
                result['summary'] = text[break_point:].strip()
            else:
                # Kelime sÄ±nÄ±rÄ±nda kes (150. karaktere yakÄ±n)
                words = text.split()
                char_count = 0
                title_words = []
                
                for word in words:
                    char_count += len(word) + 1
                    if char_count > 150:
                        break
                    title_words.append(word)
                
                result['title'] = ' '.join(title_words)
                result['summary'] = ' '.join(words[len(title_words):])
        else:
            result['title'] = text.strip()
    else:
        result['title'] = working_text.strip()
    
    return result


def extract_metadata_from_news(news_item: dict) -> dict:
    """
    Tam bir news item'dan metadata Ã§Ä±karÄ±r
    
    Ã–ncelik sÄ±rasÄ±:
    1. scraped_content iÃ§indeki veriler (en gÃ¼venilir)
    2. URL'den parse
    3. Description'dan parse
    4. Ãœst seviye fields
    """
    
    result = {
        'category': None,
        'subcategory': None,
        'title': None,
        'summary': None,
        'author': None,
        'published_date': None,
        'updated_date': None,
        'url': None,
        'images': [],
        'keywords': [],
        'paragraphs': []
    }
    
    # 1. Scraped content'ten al (en gÃ¼venilir)
    scraped = news_item.get('scraped_content', {})
    
    result['title'] = scraped.get('full_title') or news_item.get('title')
    result['summary'] = scraped.get('summary')
    result['author'] = scraped.get('author')
    result['images'] = scraped.get('images', [])
    result['keywords'] = scraped.get('keywords', [])
    result['paragraphs'] = scraped.get('paragraphs', [])
    
    # 2. URL
    result['url'] = news_item.get('link')
    
    # 3. URL'den kategori parse et
    url = news_item.get('link', '')
    if '/tr/' in url:
        parts = url.split('/tr/')
        if len(parts) > 1:
            url_category = parts[1].split('/')[0]
            result['category'] = url_category
    
    # 4. Tarih bilgisi
    result['published_date'] = news_item.get('pubDate') or news_item.get('collected_at')
    
    # 5. Description'dan eksik bilgileri tamamla
    desc = news_item.get('description', '')
    if desc:
        parsed_desc = parse_aa_description_advanced(desc)
        
        # Kategori - description'dakini URL'den olanla kombine et
        if not result['category'] and parsed_desc.get('category'):
            result['category'] = parsed_desc.get('category')
        
        # Alt kategori sadece description'dan gelir
        if parsed_desc.get('subcategory'):
            result['subcategory'] = parsed_desc.get('subcategory')
        
        # Yazar
        if not result['author'] and parsed_desc.get('author'):
            result['author'] = parsed_desc.get('author')
        
        # Summary eÄŸer scraped'de boÅŸsa description'dan al
        if not result['summary'] and parsed_desc.get('summary'):
            result['summary'] = parsed_desc.get('summary')
        
        # Tarih bilgisi description'dan daha detaylÄ± olabilir
        if parsed_desc.get('published_date'):
            result['published_date'] = parsed_desc.get('published_date')
        if parsed_desc.get('updated_date'):
            result['updated_date'] = parsed_desc.get('updated_date')
    
    # 6. image field'Ä±nÄ± kontrol et
    if not result['images']:
        img = news_item.get('image', '')
        if img:
            result['images'] = [img]
    
    return result


def test_parser():
    """Test cases"""
    
    test_cases = [
        {
            'name': 'Politika - Normal',
            'text': "PolitikaBakan MemiÅŸoÄŸlu: Åehir hastanelerimiz, birer bilim ve teknoloji Ã¼ssÃ¼ haline gelmiÅŸtirSaÄŸlÄ±k BakanÄ± Kemal MemiÅŸoÄŸlu, bugÃ¼n TÃ¼rkiye'nin dÃ¼nyanÄ±n en geliÅŸmiÅŸ saÄŸlÄ±k altyapÄ±sÄ±na sahip Ã¼lkelerinden biri olduÄŸunu belirterek, \"SaÄŸlÄ±k alanÄ±nda pek Ã§ok temel gÃ¶stergede dÃ¼nya ortalamasÄ±nÄ±n Ã¼zerine Ã§Ä±kÄ±lmÄ±ÅŸtÄ±r.\" dedi.BaÅŸak Akbulut Yazar  |17.05.2025 - GÃ¼ncelleme : 17.05.2025"
        },
        {
            'name': 'Spor - Alt kategori virgÃ¼llÃ¼',
            'text': "Spor,BasketbolKadÄ±n basketbolunda 46. sezon baÅŸlÄ±yorHalkbank KadÄ±nlar Basketbol SÃ¼per Ligi'nde 46. sezon bugÃ¼n oynanacak maÃ§larla baÅŸlayacak.Salih UlaÅŸ Åahan  |03.10.2025 - GÃ¼ncelleme : 04.10.2025"
        },
        {
            'name': 'Ekonomi - Normal',
            'text': "EkonomiTCMB BaÅŸkanÄ± Karahan: SÄ±kÄ± para politikasÄ± duruÅŸumuzu sÃ¼rdÃ¼receÄŸizTÃ¼rkiye Cumhuriyet Merkez BankasÄ± (TCMB) BaÅŸkanÄ± Fatih Karahan, sÄ±kÄ± para politikasÄ± duruÅŸunun enflasyonda kalÄ±cÄ± dÃ¼ÅŸÃ¼ÅŸ ve fiyat istikrarÄ± saÄŸlanana kadar sÃ¼receÄŸini belirtti.UÄŸur Aslanhan  |10.05.2025 - GÃ¼ncelleme : 11.05.2025"
        },
        {
            'name': 'Teknoloji - Uzun baÅŸlÄ±k',
            'text': "TeknolojiTÃ¼rkiye ve ABD'de keÅŸfedilen 6 sÃ¼lÃ¼k tÃ¼rÃ¼ dÃ¼nya bilim literatÃ¼rÃ¼ne kazandÄ±rÄ±ldÄ±TÃ¼rk ve AmerikalÄ± bilim insanlarÄ± tarafÄ±ndan yapÄ±lan saha ve laboratuvar Ã§alÄ±ÅŸmalarÄ± sonucu keÅŸfedilen 6 sÃ¼lÃ¼k tÃ¼rÃ¼, dÃ¼nya literatÃ¼rÃ¼ne kazandÄ±rÄ±ldÄ±.Ä°smail Åen  |02.05.2025 - GÃ¼ncelleme : 02.05.2025"
        },
        {
            'name': 'SaÄŸlÄ±k - Normal',
            'text': "SaÄŸlÄ±kSÃ¼lÃ¼k salgÄ±sÄ±yla iltihaplÄ± ve otoimmÃ¼n hastalÄ±klarda alternatif tedaviTÃ¼rk bilim insanlarÄ± tÄ±bbi sÃ¼lÃ¼k salgÄ±sÄ±ndaki doÄŸal bileÅŸenlerin biyoteknolojik ilaÃ§ adayÄ± olarak kullanÄ±labilmesine yÃ¶nelik Ã§alÄ±ÅŸmada baÅŸarÄ±lÄ± sonuÃ§lar elde etti.Zeynep RakipoÄŸlu  |17.02.2025 - GÃ¼ncelleme : 17.02.2025"
        }
    ]
    
    print("=" * 100)
    print("AA DESCRIPTION PARSER TEST")
    print("=" * 100)
    
    for i, test in enumerate(test_cases, 1):
        print(f"\n{'='*100}")
        print(f"TEST {i}: {test['name']}")
        print(f"{'='*100}")
        print(f"RAW: {test['text'][:80]}...\n")
        
        result = parse_aa_description_advanced(test['text'])
        
        print(f"ğŸ“ Kategori: {result['category']}")
        print(f"ğŸ“ Alt Kategori: {result['subcategory']}")
        print(f"ğŸ“° BaÅŸlÄ±k: {result['title']}")
        print(f"ğŸ“ Ã–zet: {result['summary'][:80] if result['summary'] else None}...")
        print(f"âœï¸  Yazar: {result['author']}")
        print(f"ğŸ“… YayÄ±n Tarihi: {result['published_date']}")
        print(f"ğŸ”„ GÃ¼ncelleme: {result['updated_date']}")


def test_full_extraction():
    """GerÃ§ek news item testi"""
    
    sample = {
        "guid": "3706901",
        "title": "SaÄŸlÄ±k BakanÄ± MemiÅŸoÄŸlu: DSÃ– Ä°ÅŸbirliÄŸi Merkezi'nin TÃ¼rkiye'de aÃ§Ä±lmasÄ± iÃ§in resmi sÃ¼reci baÅŸlattÄ±k",
        "link": "https://www.aa.com.tr/tr/saglik/saglik-bakani-memisoglu-dso-isbirligi-merkezinin-turkiyede-acilmasi-icin-resmi-sureci-baslattik/3706901",
        "description": "SaÄŸlÄ±kSaÄŸlÄ±k BakanÄ± MemiÅŸoÄŸlu: DSÃ– Ä°ÅŸbirliÄŸi Merkezi'nin TÃ¼rkiye'de aÃ§Ä±lmasÄ± iÃ§in resmi sÃ¼reci baÅŸlattÄ±kSaÄŸlÄ±k BakanÄ± Kemal MemiÅŸoÄŸlu, \"DSÃ– ile yÃ¼rÃ¼ttÃ¼ÄŸÃ¼mÃ¼z gÃ¶rÃ¼ÅŸmeler sonucunda, GETAT alanÄ±nda bir DSÃ– Ä°ÅŸbirliÄŸi Merkezi'nin TÃ¼rkiye'de aÃ§Ä±lmasÄ± iÃ§in resmi sÃ¼reci baÅŸlattÄ±k.\" dedi.Hikmet Faruk BaÅŸer  |03.10.2025 - GÃ¼ncelleme : 03.10.2025",
        "pubDate": "03.10.2025",
        "category": None,
        "image": "",
        "scraped_content": {
            "url": "https://www.aa.com.tr/tr/saglik/saglik-bakani-memisoglu-dso-isbirligi-merkezinin-turkiyede-acilmasi-icin-resmi-sureci-baslattik/3706901",
            "full_title": "SaÄŸlÄ±k BakanÄ± MemiÅŸoÄŸlu: DSÃ– Ä°ÅŸbirliÄŸi Merkezi'nin TÃ¼rkiye'de aÃ§Ä±lmasÄ± iÃ§in resmi sÃ¼reci baÅŸlattÄ±k",
            "summary": "...",
            "keywords": ["3. Geleneksel ve TamamlayÄ±cÄ± TÄ±p Kongresi", "SaÄŸlÄ±k BakanÄ± Kemal MemiÅŸoÄŸlu"],
            "images": [],
            "author": None
        }
    }
    
    print("\n" + "=" * 100)
    print("FULL NEWS EXTRACTION TEST")
    print("=" * 100)
    
    result = extract_metadata_from_news(sample)
    
    print(f"\nğŸ“ Kategori: {result['category']}")
    print(f"ğŸ“ Alt Kategori: {result['subcategory']}")
    print(f"ğŸ“° BaÅŸlÄ±k: {result['title']}")
    print(f"ğŸ“ Ã–zet: {result['summary'][:80] if result['summary'] else None}...")
    print(f"âœï¸  Yazar: {result['author']}")
    print(f"ğŸ“… Tarih: {result['published_date']}")
    print(f"ğŸ”— URL: {result['url']}")
    print(f"ğŸ–¼ï¸  Resimler: {len(result['images'])} adet")
    print(f"ğŸ”‘ Keywords: {result['keywords']}")


if __name__ == "__main__":
    test_parser()
    print("\n\n")
    test_full_extraction()